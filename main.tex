\documentclass[12pt,twoside,a4paper]{report}

\include{config/package}
\include{config/layout}


\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\include{config/capa}
\include{sections/resumo}
\include{sections/abstract}
%\include{sections/biografia}
\include{sections/dedicatoria}
\include{sections/agradecimentos}
\include{sections/sumario}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%TEXTO%%%%%%%%%%%%%%%

\include{sections/introducao}
\label{c1}
\include{sections/numeros_magicos}
\include{sections/foca}


\chapter{Capítulo com muitas fórmulas} \label{ometodo}

Neste capítulo realizaremos uma detalhada descrição do método de DMC na seção \ref{alg_padr}. ....

\section{O algoritmo padrão}
\label{alg_padr}

Se escrevemos a equação de Schroedinger,

\begin{equation} \label{eschrodinger}
i\hbar \frac{\partial \Psi}{\partial t}= -\frac{\hbar^2}{2m}
\nabla_R^2 \Psi + V\Psi,
\end{equation}

\noindent em tempo imaginário ($\tau=it/\hbar$), vemos que esta
pode ser interpretada como uma equação de difusão da forma

\begin{equation} \label{eischrodinger}
\frac{\partial \Psi}{\partial \tau}= D \nabla_R^2 \Psi - V
\Psi = - H \Psi,
\end{equation}

\noindent onde $D=\hbar^2/2m$ é a constante de difusão.

Mediante esta transformação, as soluções gerais da equação
(\ref{eschrodinger}) são
modificadas para a forma

\begin{equation} \label{solim}
\Psi({\bf R},\tau) = \sum_i \phi_i ({\bf R}) \exp  \left( - E_i
\tau \right),
\end{equation}

\noindent onde $\phi_i$ e $E_i$ são as funções e valores próprios
respectivamente da equação de Schroedinger independente do tempo.
Notemos que o fato de utilizarmos tempo imaginário transforma a
solução (\ref{solim}) em uma soma de termos exponenciais decrescentes. Como uma
constante
$E_T$ pode ser
introduzida na energia potencial do sistema sem modificar a forma
funcional das
autofunções $\phi_i({\bf R})$, a equação (\ref{eischrodinger}) e a
sua solução
(\ref{solim}) podem ser reescritas como:

\begin{equation} \label{eqsch2}
\frac{\partial \Psi}{\partial \tau}= D \nabla_R^2 \Psi -
(V-E_T) \Psi = -H \Psi
\end{equation}

\noindent e

\begin{equation} \label{solim2}
\Psi({\bf R},\tau) = \sum_i \phi_i ({\bf R}) \exp  \left( -
(E_i - E_T) \tau
\right);
\end{equation}

\noindent onde a Hamiltoniana do sistema é dada agora por $H =
T+(V-E_T)$. Como
consequência disto, para uma evolução temporal longa o suficiente da
solução
$\Psi({\bf R},\tau)$
(\ref{solim2}), e ajustando adequadamente o valor da constante
$E_T$, o único estado sobrevivente é o fundamental. Pode-se
dizer então que a evolução do sistema no tempo
imaginário projeta o sistema no seu estado fundamental.

A equação (\ref{eqsch2}) possui uma solução formal do tipo

\begin{equation} \label{esimpli}
|\Psi(\tau)\rangle = G |\Psi^{'}(0)\rangle,
\end{equation}

\noindent onde $G = \exp(-\tau H)$. Integrando a equação (\ref{esimpli}) 
obtemos a
seguinte expressão

\begin{equation} \label{intpsi}
\Psi({\bf R},\tau) = \int {\bf dR}^{'} G({\bf R^{'}} \rightarrow
{\bf R}, \tau) \Psi({\bf R}^{'}, 0),
\end{equation}

\noindent com a qual podemos evoluir uma representação da função de onda do 
sistema em um
intervalo de tempo
$\triangle \tau$. A função de Green $G({\bf R}^{'}
\rightarrow {\bf R}, \tau)$ da equação (\ref{intpsi}) pode ser
interpretada
como a probabilidade de transição das partículas da
posição
${\bf R}^{'}$ para
${\bf R}$ num tempo $\tau$. A representação da função de Green
$G({\bf R}^{'}
\rightarrow {\bf R}, \tau)$ no espaço das coordenadas é dada por

\begin{equation} \label{funcaogreen}
G({\bf R}^{'} \rightarrow {\bf R}, \tau) = \langle {\bf
R}|\exp[-\tau \hat{T} -
\tau (\hat{V} - E_T)]|{\bf R}^{'} \rangle,
\end{equation}

\noindent onde $\hat{T}$ e $\hat{V}$ são os operadores da energia
cinética e
potencial respectivamente. Como notação, a
função de Green
(\ref{funcaogreen}) vai ser representada por $G(R,R^{'})$.

Em geral, o cálculo da função $G(R,R^{'})$ não é tarefa fácil mas
pode ser
simplificada se usarmos a chamada aproximação de tempo pequeno
(``short-time
aproximation''). Isto implica expandir o comutador da função de
Green da equação
(\ref{funcaogreen}) para tempos pequenos. Realizando isto se obtém
uma forma da função de Green dada por

\begin{eqnarray} \label{gaprox}
G(R,R^{'}) &\cong& \langle {\bf R}|\exp(-\triangle \tau
\frac{\hat{V}}{2})
\exp(-\triangle \tau \hat{T}) \exp(-\triangle \tau
\frac{\hat{V}}{2})|{\bf
R}^{'}\rangle \nonumber \times \\ &&
\exp(\triangle \tau E_T) \nonumber \\ &=&
\exp(-(\frac{\triangle\tau}{2})\{V(R) +
V(R^{'})\} + \triangle\tau E_T) \nonumber \times \\ && \langle
{\bf R}|
\exp-(\triangle\tau \hat{T})|{\bf R}^{'} \rangle \nonumber \\ &=&
G_b(R,R^{'})
G_d(R,R^{'}).
\end{eqnarray}

\noindent Aqui $G_d(R,R^{'})$ é a solução ordinária da equação da
difusão e
$G_b(R,R^{'})$ pode ser interpretada como a razão de decaimento ou 
crescimento associada à configuração $R$ das partículas.
Explicitamente estas funções são
dadas respectivamente por

\begin{equation} \label{greenb}
G_b(R,R^{'}) = \exp(- (\frac{\triangle\tau}{2}) [V(R) + V(R^{'})]
+ \triangle\tau
E_T)
\end{equation}

\noindent
e

\begin{equation} \label{greend}
G_d(R,R^{'}) = (4 \pi D \triangle\tau)^{-\frac{3N}{2}}
\exp[-\frac{({\bf R} - {\bf
R}^{'})^2}{4D\triangle\tau}].
\end{equation}

É importante mencionar que a expressão da função de Green (\ref{gaprox}) é correta só
até ordem
O($\tau^3$). Isto implica que para obter resultados 
exatos, devemos usar
intervalos de tempo $\triangle\tau$ pequenos e
realizar uma extrapolação dos resultados para $\triangle \tau \rightarrow
0$ (veja entretanto comentários no Capítulo \ref{asimulação}). O valor de 
$\triangle \tau$ é um
parâmetro
em nossos cálculos.

Um conjunto inicial de configurações é propagado por um
intervalo de tempo
$\triangle\tau$ mediante o uso da
função de Green $G(R,R^{'})$
(\ref{gaprox}). Isto é feito através dos processos
de difusão e
``branching''. Para difundir as configurações é preciso aplicar a
função $G_d(R,R^{'})$ (\ref{greend})
sobre cada uma das partículas de cada configuração. Isto se reduz a
deslocar cada uma das
coordenadas das partículas, por exemplo $x$, de acordo com

\begin{equation}
x = x^{'} + \chi \; ,
\end{equation}

\noindent onde $\chi$ é um número aleatório amostrado de uma
Gaussiana de variança
$2D\triangle\tau$ e média zero. Neste caso temos que fazer $3N$ atualizações das
posições das partículas
para propagar uma
configuração, sendo $N$ o número de partículas do sistema. Alternativamente, é
possível deslocar todas as partículas simultaneamente com pequenas modificações no
algoritmo.

Inicialmente cada uma das configurações começa a sua evolução
carregando um peso
$w^{'}$ igual a um. Após a evolução de cada uma das configurações, os pesos destas
são atualizados usando a função $G_b(R,R^{'})$ (\ref{greenb}). Estes pesos são
atualizados de acordo com:

\begin{equation} \label{atpesos}
w=w^{'}G_b(R,R^{'}).
\end{equation}

Após a propagação de todas as configurações chegamos a uma nova
geração. Neste momento é possível realizar uma
amostragem da função de onda $\Psi(R,\tau)$. Por motivos de
eficiência, a quantidade
de configurações usadas para estimar $\Psi(R,\tau)$ varia, este
é o chamado processo
de ``branching''; o qual será explicado na Seção seguinte.

\section{Amostragem de importância}

Existem vários problemas associados ao método como implementado na seção anterior.
Um deles surge do
fato de que para certos potenciais (como o potencial de Coulomb) a
função
$G_b(R,R^{'})$ aumenta muito o número das configurações quando
as partículas estão
muito próximas, já que $V(r) \rightarrow -\infty$.
Outro problema prático com relação ao
método surge do fato que as partículas podem perder muito tempo navegando 
por
regiões do espaço
de configuração que não são relevantes para o cálculo final. Para
eliminar estes problemas, se multiplica a equação de Schroedinger da equação 
(\ref{eqsch2}) por uma
função $\Psi_G$ conhecida, que aproximadamente representa o
estado
fundamental do sistema. Este procedimento é chamado de
amostragem de importância. Uma vez feito isto, a equação de Schroedinger em 
tempo
imaginário
(\ref{eqsch2}) pode ser reescrita como

\begin{equation} \label{eresschroedinger}
\frac{\partial f}{\partial \tau} = D \nabla_R^2 f - D
\nabla_R \cdot [f{\bf F}] + [E_T - E_L({\bf R})] f,
\end{equation}

\noindent onde $f=\Psi_G\Psi$, $E_L({\bf R})={H \Psi_G}/{\Psi_G}$ e ${\bf 
F}=
2\nabla_R \ln
\Psi_G$. Neste caso $E_L$ é a energia local do sistema e a função
${\bf F}$ atua como
uma força de arraste imposta na difusão. A presença da função
${\bf F}$ na equação
(\ref{eresschroedinger}) permite que as partículas sejam
arrastadas para regiões do
espaço onde $f$ é importante.

Para resolver a equação (\ref{eresschroedinger}) notemos que sua
função de Green
satisfaz

\begin{equation}
\frac{\partial \tilde{G}}{\partial \tau} = - \tilde{H}\tilde{G} =
- (\tilde{T} +\tilde{V}) \tilde{G},
\end{equation}

\noindent onde o operador $\tilde{T}$ é dado por

\begin{equation}
\tilde{T}= - D \nabla_R^2 + D  \nabla_R \cdot {\bf F}+ D
{\bf F} \cdot \nabla_R
\end{equation}

\noindent e $\tilde{V}$ como

\begin{equation}
\tilde{V} = E_L - E_T.
\end{equation}

\noindent Desta forma, e utilizando a aproximação de tempos pequenos, 
podemos
escrever a função de Green do sistema como

\begin{equation} \label{fgreen2}
\tilde{G}(R,R^{'})= \tilde{G}_b(R,R^{'}) \tilde{G}_d(R,R^{'}),
\end{equation}

\noindent onde

\begin{equation} \label{gb2}
\tilde{G}_b(R,R^{'}) = \exp(- (\frac{\triangle\tau}{2}) [E_L(R)
+ E_L(R^{'})] + \triangle\tau E_T)
\end{equation}

\noindent e

\begin{equation} \label{gd2}
\tilde{G}_d(R,R^{'}) =  (4 \pi D
\triangle\tau)^{-\frac{3N}{2}} \exp \left[- \frac{({\bf R} - {\bf
R}^{'} -
D\triangle\tau {\bf F({\bf R}^{'})})^2}{4D\triangle\tau} \right].
\end{equation}

\noindent A evolução temporal de $f$ é dada por

\begin{equation} \label{it}
f(R,\tau) = \int dR^{'} \,
\tilde{G}_d(R,R^{'})\tilde{G}_b(R,R^{'}) f(R^{'},
\tau-\triangle \tau).
\end{equation}

Notemos que o fato de introduzir a função $f$ na equação
(\ref{eqsch2}) fez com que a
função peso $\tilde{G}_b(R,R^{'})$ não dependa mais diretamente
do potencial $V(R)$ e sim da energia local $E_L$ que é mais
estável e não apresenta as possíveis divergências do potencial $V(R)$. A 
forma da função
$\tilde{G}_d(R,R^{'})$ é a mesma que a
do propagador $G_d(R,R^{'})$ com um termo extra,
o da força de arraste ${\bf F}$.

Para implementar a equação (\ref{it}) em forma computacional, e
preciso primeiramente
ter um conjunto de configurações iniciais não correlacionadas do sistema. 
Este
conjunto é amostrado de $|\Psi_G|^2$ usando o algoritmo de Metropolis, sendo 
$\Psi_G$ uma função
guia conhecida que aproximadamente representa o
estado
fundamental do sistema. A seguir se
difundem as partículas aplicando a função $\tilde{G}_d(R,R^{'})$.
Isto é realizado deslocando cada uma das partículas, variando por exemplo a
coordenada $x$ de acordo com

\begin{equation} \label{desl}
x = x^{'} + \chi + D \triangle \tau F(R^{'}).
\end{equation}

\noindent onde $\chi$ é um número aleatório amostrado de uma
Gaussiana de variança $2D\triangle\tau$ e média zero. Notemos que agora 
precisamos calcular a
força de
arraste ${\bf F}$ cada
vez que pretendamos mudar as coordenadas de uma partícula. Uma vez
feita a difusão, as
configurações são pesadas usando $\tilde{G}_b(R,R^{'})$ (\ref{gb2}) na 
equação (\ref{atpesos}).

Após a propagação de todas as configurações chegamos a uma nova
geração. Neste momento é possível realizar uma
amostragem de quantidades de interesse do sistema como
uma média ponderada de todas as configurações. Por motivos de
eficiência, a quantidade
de configurações usadas nestas amostragens varia, este
é o chamado processo
de ``branching''. O número de configurações varia de acordo com as
seguintes regras. Se $w$ é maior que 2, a configuração é duplicada e cada uma das
copias vai
carregar metade deste peso. Por outro lado, se duas configurações, $R_i$ e 
$R_j$,
possuem pesos menores
que 0.5, só uma delas vai sobreviver carregando um peso dado por
$w_i+w_j$. A decisão de
qual delas sobrevive é feita amostrando $r=w_i/(w_i+w_j)$. Isto
é, sorteamos um
número aleatório $\xi$ e comparamos ele com $r$. Se $r$ é menor
que $\xi$ então
mantemos a configuração $R_j$, caso contrario mantemos a
configuração $R_i$. Por
último, se o peso da configuração se encontra no intervalo de 0.5 e
2, uma copia só é feita com peso $w$. Os valores dos pesos no qual realizamos o
``branching'' podem ser
alterados, nós só precisamos de regras que não levem a resultados 
tendenciosos
ou resultem em um
esquema ineficiente de cálculo.

Finalmente, quantidades de interesse como a energia de ligação podem ser 
computadas de acordo
com

\begin{eqnarray} \label{ener}
E_m = \frac{\sum_i w(R_i)E_L(R_i)}{\sum_i w(R_i)},
\end{eqnarray}

\noindent onde a soma é feita sobre todas as configurações de uma
dada geração.

O número total de configurações na evolução do sistema é controlado 
ajustando o valor de
$E_T$. Procuramos manter este número de configurações constante.
Experimentamos mudanças
heurísticas e
automáticas do valor de $E_T$, neste último caso dada por:

\begin{equation} \label{et}
E_T = E_0 + \kappa \ln ({\rm T_p}/{\rm C_p}),
\end{equation}

\noindent onde $E_0$ e $\kappa$ são parâmetros, ${\rm T_p}$ é a população
alvo e ${\rm C_p}$
a população atual. Para nossos propósitos os resultados foram
equivalentes com as
duas formas de mudar $E_T$. Ajustes no $E_T$ foram geralmente providenciados 
uma vez a cada 20
gerações.

É sabido\cite{cep79,rey82} que estimativas das quantidades de
interesse como a
energia da equação (\ref{ener}) são tendenciosas. Estas tendências são
devidas a dois motivos:
controle da população e do fato que o valor esperado de um quociente
não é o quociente dos
valores esperados. A determinação de
resultados satisfatórios precisam de uma
avaliação correta das tendências destes ou pelo menos de um limite para sua
magnitude. As tendências podem ser
reduzidas aumentando o tamanho da população. Observamos que
para um sistema de
hélio com 108/64 partículas, 400 configurações fornecem
resultados nos quais erros
associados a estas tendências são menores que os erros estatísticos.
Certamente métodos mais
sofisticados \cite{umr93,ass00} para suprimir as tendências podem ser
aplicados.

Para melhorar a aproximação feita na função de Green (\ref{fgreen2})
\cite{rey82,cep81}, aceitamos deslocamentos com uma probabilidade dada por

\begin{equation} \label{db}
p_{\rm aceito}(R^{'}\rightarrow R)={\rm
min}\left[1,\frac{\tilde{G}_d(R^{'},R)\Psi_G^2(R)}{\tilde{G}_d(R,R^{'})\Psi_G^2(
R^{'})}\right].
\end{equation}

\noindent Escolhemos um valor de $\triangle \tau$ que forneça
uma aceitação de cerca de 99\%. A condição da equação (\ref{db}) impõe o balanço
detalhado na função de
Green (\ref{fgreen2}),
e restaura esta propriedade da função de Green exata (\ref{funcaogreen}).
Independente do $\triangle\tau$
usado, esta condição também garantiria a correta amostragem das
configurações se
hipoteticamente usamos como $\Psi_G$ a função de onda exata do
problema. Nesse caso,
a implementação do método de DMC se reduz a um Monte Carlo
variacional, sendo os
deslocamentos das partículas amostrados via $\tilde{G}_d(R,R^{'})$.

Com a idéia de minimizar flutuações em $\tilde{G}_b(R,R^{'})$, um
tempo efetivo é usado \cite{rey82,umr93}. Este é dado por
$\Delta\tau_{eff}=\Delta\tau (\Delta
\rho^2_a/\Delta \rho^2)$, onde $\Delta \rho^2$ é o deslocamento quadrático
médio de todos os deslocamentos propostos na
difusão e $\Delta
\rho^2_a$ é uma quantidade similar mas com respeito aos
deslocamentos aceitos no
processo.



\chapter{Capítulo com tabelas} \label{mpot}


\begin{table} [h]
\begin{center}
\caption{\label{parteo}
{\sl Parâmetros do ajuste das equações de estado para as fases líquida e sólida 
usando as energias de
ligação calculadas para os respectivos potenciais. ES-Exp denota os 
parâmetros do ajuste dos
valores experimentais da energia de ligação (ver Apêndice \ref{esop}). Na 
última linha, para a
fase líquida, damos valores experimentais das correspondentes quantidades. As 
unidades de
$E_0$, $A$ e $B$ estão expressos em K.}}
\vspace{0.7cm}
\begin{tabular}{|ccccc|}
\hline
\hline
Potencial & $\rho_0$ $(\rm{nm}^{-3})$ & $E_0$ & $A$ & $B$ \\
\hline
& \multicolumn{3}{c}{\rm \bf Líquido} &  \\
$V_{pDJ}$ & $21.820 \pm 0.019$ & $-7.200 \pm 0.002$ & $13.31 \pm 0.25$ & 
$12.2 \pm 1.7$ \\
$V_{prDJ}$ & $21.804 \pm 0.019$ & $-7.178 \pm 0.002$ & $13.27 \pm 0.25$ & 
$12.1 \pm 1.7$ \\
$V_{hDJ}$ & $21.681 \pm 0.017$ & $-7.124 \pm 0.002$ & $13.27 \pm 0.22$ & 
$11.4 \pm 1.7$ \\
$V_{A}$ & $21.683 \pm 0.022$ & $-7.117 \pm 0.004$ & $13.42 \pm 0.37$ & 
$1.1 \pm 2.1$
\\
ES-Exp\footnotemark[1] & $21.820 \pm 0.004$ & $-7.1701 \pm 0.0001$ & $13.449 
\pm 0.086$ & $7.82
\pm
0.30$ \\
Exp. & 21.834\footnotemark[2] & -7.170\footnotemark[3] & & \\
& \multicolumn{3}{c}{\rm \bf Sólido} &  \\
$V_{pDJ}$ & $25.68 \pm 0.14$ & $-6.221 \pm 0.019$ & $21.0 \pm 1.9$ & $13.9 
\pm 1.8$ \\
$V_{prDJ}$ & $25.69 \pm 0.14$ & $-6.192 \pm 0.019$ & $21.2 \pm 1.9$ & $13.8 
\pm 1.8$ \\
$V_{hDJ}$ & $25.77 \pm 0.16$ & $-6.100 \pm 0.022$ & $23.0 \pm 1.9$ & $12.5 
\pm 1.9$ \\
ES-Exp\footnotemark[4] & $26.02 \pm 0.70$ & $-6.220 \pm 0.097$ & $25.6 \pm 
7.7$ & $6.8 \pm 7.3$
\\
\hline
\end{tabular}
\end{center}

$^{1}$ {\rm \small Ajustado com os dados da Ref. \cite{bru87}.}

$^{2}$ {\rm \small Referência \cite{ber76}.}

$^{3}$ {\rm \small Referência \cite{bru87}.}

$^{4}$ {\rm \small Ajustado com os dados da Ref. \cite{edw65}.}

\vspace{2cm}
\end{table}

Como podemos ver da Tabela \ref{parteo}, as diferenças
entre as
densidades de equilíbrio usando as equações de estado analíticas dos 
potenciais $V_{pDJ}$,
$V_{prDJ}$ e $V_{hDJ}$ e aquelas obtidas do ajuste dos dados experimentais 
ES-Exp foram 0, 0.07 e 0.6\% respectivamente. Notamos que o 
melhores resultados foram obtidos usando os
potenciais $V_{pDJ}$ e $V_{prDJ}$. Ambos resultados estão dentro de seus 
erros estatísticos em excelente acordo com o valor calculado da ES-Exp e também com o
valor experimental para a densidade de 
equilíbrio de
Berthold \cite{ber76}; outro valor próximo é reportado na Ref. \cite{bru87}. É
interessante notar que nossos resultados para a densidade de equilíbrio esta em
acordo, seja com o valor obtido do nosso ajuste da equação de estado com dados
experimentais, seja com o valor experimental publicado \cite{ber76}. Entretanto, o
valor de 
Berthold, 21.834 ${\rm nm^{-3}}$, não esta em acordo com aquele obtido 
usando a ES-Exp, apesar da diferença de apenas 0.06\% entre estes valores.


\begin{table}[h]
\begin{center}
\caption{\label{kpc}
{\sl Valores da compressibilidade isotérmica $K$ (${\rm atm}^{-1}$), pressão $P$ 
(atm) e velocidade
do som $c$ (m/s) calculados na densidade de equilíbrio experimental, 21.834 ${\rm
nm^{-3}}$,
usando 
as equações de estado analíticas para os respectivos
potenciais e energias de ligação experimentais. Na última linha apresentamos dados
experimentais.}}
\vspace{0.7cm}
\begin{tabular}{|cccc|}
\hline
\hline
Potencial & $K$ & $P$ & $c$ \\
\hline
$V_{pDJ}$ & $0.0126 \pm 0.0002$ & $0.050 \pm 0.060$ & $235.67 \pm 0.45$ \\
$V_{prDJ}$ & $0.0126 \pm 0.0002$ & $0.107 \pm 0.060$ & $235.86 \pm 0.45$ \\
$V_{hDJ}$ & $0.0122 \pm 0.0002$ & $0.566 \pm 0.063$ & $240.23 \pm 0.52$ \\
$V_{A}$ & $0.0121 \pm 0.0003$ & $0.561 \pm 0.085$ & $239.83 \pm 0.70$ \\
ES-Exp & $0.01245 \pm 0.00008$ & $0.051 \pm 0.017$ & $236.81 \pm 0.23$ \\
Exp & $0.0123$\footnotemark[1] & ----- & $238.30$\footnotemark[2] \\
\hline
\end{tabular}
\end{center}

$^{1}$ {\rm \small Valor calculado usando dados
experimentais da
Referência \cite{abr70}.}

$^{2}$ {\rm \small Referência \cite{abr70}.}

\vspace{9cm}
\end{table}


Os valores destas quantidades também foram calculados
autoconsistentemente, {\sl i.e.}, calculados nas densidades de equilíbrio $\rho_0$
obtidas
diretamente das equações de estado analíticas da Tabela \ref{parteo}. 

\section{Discussão}
Nossos resultados ....


\chapter{Conclusões} \label{conclusões}

\newpage

$ $

\newpage


%% \bibliography{./nsav}
%% \bibliographystyle{unsrt}
\addcontentsline{toc}{chapter}{Bibliografia}
\bibliographystyle{acm}
\bibliography{references.bib}


\chapter*{Apêndices}
\markboth{Apêndices}{Apêndices}
\addcontentsline{toc}{chapter}{Apêndices}


\appendix
\title{Apêndices}

\chapter{Condições de contorno} \label{ccon}

Para simular o hélio nas fases líquida e sólida nas
densidades estudadas, utilizamos uma caixa de simulação com 64 ou 108
partículas. Como a idéia fundamental é conseguir descrever as
características do hélio nas fases sólida e líquida mediante esta pequena
caixa de simulação e tão reduzido número de partículas, usamos a
aproximação padrão de fazer imagens periódicas da caixa de simulação. O resultado
deste
procedimento em duas dimensões esta esquematizado na Figura
\ref{condcont}. A simulação
só é feita na caixa central, nas caixas imagens vão-se repetir os
mesmos deslocamentos das partículas da caixa de simulação. Notemos
que as dimensões da caixa de simulação deve ser ajustada de tal forma
que a densidade das partículas no seu interior seja a densidade a ser
estudada. Se uma partícula consegue sair da caixa de simulação, uma outra 
entra imediatamente
dentro da caixa. Isto e feito pelo ingresso de uma partícula de uma caixa 
vizinha à caixa de
simulação, desta
forma o número de partículas na caixa de simulação permanece constante.

\begin{figure} [h]
\vspace{0.7cm}
\begin{center}
    \includegraphics[scale=0.3]{contorno}
\end{center}
\caption{\label{condcont} {\sl Condições periódicas de contorno na simulação.}}
\end{figure}

Este 
processo esta
esquematizado na Figura \ref{condcont}.
Para verificar se uma partícula conseguiu sair da caixa de simulação e 
consequentemente outra
entrou, usamos condições de contorno periódicas. Para
exemplificar isto consideremos que após um deslocamento a partícula ocupa
a posição ($x,y,z$). Para verificar se a coordenada $x$ ($y,z$) da partícula
encontra-se dentro ou fora da caixa utilizamos a função definida como

\begin{equation} \label{b1}
x=x+\frac{L_x}{2} \; {\rm anint}(-2x/L_x)
\end{equation}

\noindent onde $L_x$ representa o comprimento do lado $x$ da caixa de
simulação, anint é uma função da forma

\begin{equation}
{\rm anint} = \left\{\begin{array}{l}
    \hspace{0.3cm}  1, \; \; {\rm se} \; \; \;  -2x/L_x > 1  \\
    \hspace{0.3cm}  0, \; \; {\rm se} \; \; \; -1 \le -2x/L_x \le 1 \\
             -1, \; \; {\rm se} \; \; \; -2x/L_x < 1
                     \end{array} \right.
\end{equation}

\newpage

\chapter{Parâmetros dos potenciais usados} \label{potparam}

Alguns parâmetros são apresentados com um número de casas maior que o número
significativo para
garantir precisão computacional.

\section{HFD-B3-FCI1 - $V_h$}

\begin{equation} \nonumber
\begin{array}{ccc}
\epsilon=10.9560000 \; {\rm K}, & & C_6=1.35186623, \\
r_m=2.9683000 \; {\rm \mathring{A}}, & & C_8=0.41495143,\\
D=1.43800000, & & C_{10}=0.17151143, \\
\alpha=10.5717543, & & A=1.86924404 \times 10^5, \\
\beta=-2.07758779.
\end{array}
\end{equation}

\section{Korona e colaboradores - $V_p$}

\begin{equation} \nonumber
\begin{array}{ccccc}
C_6=1.4609778 \; {\rm (a.u)}, & & C_8=14.117855 \; {\rm (a.u)} ,& & 
C_{10}=183.69125 \; {\rm
(a.u)}, \\
C_{12}=3265 \; {\rm (a.u)}, & & C_{14}=76440 \; {\rm (a.u)}, & & 
C_{16}=2275000 \; {\rm (a.u)},
\\
A=2074364.26 \; {\rm K}, & & \alpha=1.88648251 \; {\rm bohr}^{-1}, & & 
\beta=-0.062001349 \;
{\rm
bohr}^{-2}, \\
b=1.94861295 \; {\rm bohr}^{-1}.
\end{array}
\end{equation}

\section{Janzen e colaboradores - $V_{pr}$}

Os valores dos parâmetros para este potencial são os mesmos que para o 
potencial $V_p$. A função
de retardo $f_r(r)$ esta definida como


\begin{table}[h]
\centering
{\small
\begin{tabular}{|ccc|}
\hline \hline
{\rm Intervalo $r$} & $f_r(r)$ & $p_1$ (a.u.) \\
\hline \hline
$0 \le r <5.7$ & 1 & ----- \\
$5.7 \le r <10$ & $p_1+p_2r+p_3r^2+p_4r^3$ & $9.860029\times10^{-1}$ \\
$10 \le r <10^2$ & $1-p_1-p_2r^{0.5}-p_3r-p_4r^{1.5}-p_5r^2$ & 
$-1.62343\times10^{-3}$ \\
$10^2 \le r <2\times10^2$ & $(1+p_1+p_2r^{0.5}+p_3r+p_4r^2)/(1.2+0.8p_5r)$ &
$8.82506\times10^{-2}$ \\
$2\times10^2 \le r <10^3$ & ${\rm ln}(r(p_1r^{0.4}+p_2r^{0.5}+p_3r^{0.6}
+p_4r^{0.7}+p_5r^{0.8}))$ & $1.488897$ \\
$10^3 \le r <10^4$ & $p_1+p_2/r+p_3/r^2+p_4/r^3+p_5/r^4$ & 
$6.184108\times10^{-6}$ \\
$10^4 \le r <10^5$ & $p_1+p_2/r+p_3/r^2+p_4/r^3+p_5/r^4$ & 
$-1.107002\times10^{-7}$ \\
\hline \hline
\end{tabular}}
\end{table}

\begin{table}[h]
\centering
{\small
\begin{tabular}{|ccccc|}
\hline \hline
{\rm Intervalo $r$} & $p_2$ (a.u.)& $p_3$ (a.u.)& $p_4$ (a.u.)& $p_5$ 
(a.u.)\\
\hline \hline
0 $\le$ r <5.7 & ----- & ----- & ----- & ----- \\
5.7 $\le$ r <10 & $5.942027\times10^{-3}$ & $-7.924833\times10^{-4}$ & 
$3.172548\times10^{-5}$ &
----- \\
10 $\le$ r <$10^2$ & $2.22097\times10^{-3}$ & $-1.17323\times10^{-3}$ & 
$3.00012\times10^{-4}$ &
$-1.05512\times10^{-5}$ \\
$10^2$ $\le$ r <$2\times10^2$ & $3.81846\times10^{-2}$ & 
$-1.72421\times10^{-3}$ &
$4.74897\times10^{-7}$ & $3.0445706\times10^{-3}$ \\
$2\times10^2$ $\le$ r <$10^3$ & $-2.123572$ & $1.043994$ & 
$-1.898459\times10^{-1}$ &
$6.479867\times10^{-3}$ \\
$10^3$ $\le$ r <$10^4$ & $3.283043\times10^2$ & $1.367922\times10^3$ & 
$-4.464489\times10^7$ &
$1.365003\times10^{10}$ \\
$10^4$ $\le$ r <$10^5$ & $3.284717\times10^2$ & $-9.819846\times10^2$ & 
$-1.953816\times10^7$ &
$-1.079712\times10^{11}$ \\
\hline \hline
\end{tabular}}
\end{table}

\section{HFDHE2 - $V_A$}

\begin{equation} \nonumber
\begin{array}{ccc}
\epsilon=10.8 \; {\rm K}, & & C_6=1.3732412, \\
r_m=2.9673 \; {\rm \mathring{A}}, & & C_8=0.4253785,\\
D=1.241314, & & C_{10}=0.178100, \\
\alpha=13.353384, & & A=0.5448504 \times 10^6.
\end{array}
\end{equation}

\section{Cohen e Murrell - $V_3$}

\begin{equation} \nonumber
\begin{array}{ccccc}
k=2.7 \; {\rm \mathring{A}}, & & \alpha=3.446 \; {\rm \mathring{A}^{-1}}, & 
& l=1.15, \\
c_0=-1957.895, & & c_1=673.186, & & c_2=-188.491, \\
c_3=3664.836, & & c_4=-1655.476, & & c_5=244.090, \\
c_6=4129.947, & & c_7=-1726.015, & & c_8=177.661, \\
c_9=2693.277, & & c_{10}=-1096.591, & & c_{11}=154.063, \\
c_{12}=6011.520, & & c_{13}=-2618.297, & & c_{14}=296.384 \;.
\end{array}
\end{equation}

\noindent Os parâmetros $c_i$ estão nas unidades apropriadas, {\sl i.e.}, $c_0=eV_h$, 
$c_1=eV_h/{\rm \mathring{A}}$, etc.

\noindent Aqui $1eV_h=0.036726 E_h$.

\end{document}


